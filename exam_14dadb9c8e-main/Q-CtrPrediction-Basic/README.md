# Q-CtrPrediction-Basic

与えられたデータを使い、[問1](no1)に解答してください。

## 提出物

実行するコードを`no1`ディレクトリに格納し、GitHubにプッシュしてください。
各問のディレクトリをカレントディレクトリとして、`./run.sh`で起動できるようにしてください。

`run.sh`を実行すると、実行時ディレクトリからの相対パスで`../data`というディレクトリに`submission.csv`というファイルが結果として出力されるようにしてください。
以下で説明する入力用データは`../data`に入っているものとして実装してください。
データの読み込みと書き出しを行うPythonによる実装例は各問題ディレクトリに入っているので参考にしてください。
参考実装はPythonでの標準出力から書き出した例ですが、pandasなどのライブラリや、R言語などの他言語を利用した出力でも構いません。

尚、採点時は`../data`ディレクトリは採点用のデータに上書きされます。一時的にディスクに書き出したいデータがある場合は各問題のディレクトリ内など、別の場所に書き出すようにしてください。

ローカル環境で試しにコードを実行する際に、入出力パスを独自のものに設定したままコードを提出してしまうと、提出されたコードがうまく実行されませんので注意してください。
また、Windowsを使っている人は、入出力パスを「¥」区切りで記述したまま提出しないように注意してください。提出後のコードはLinux環境で実行されます。提出コードの実行環境の詳細については[問題全体に関するREADME](../README.md)を参考にしてください。


## データ

以下のようなデータを使用します。

```
data
├── category.csv
├── test
│   ├── 2020-02-01
|   |      ...
│   └── 2020-02-28
└── train
    ├── 2020-01-01
    |      ...
    └── 2020-01-31
```

- [data](data)にはローカル開発用のデータが入っています。ローカルでのモデル構築に利用してください。
- 採点時には別のデータが使われますが、形式は同一です。
- [data](data)にあるデータは2万行ほどですが、採点の際には最大500万行のデータが使われます。
- この問題のデータは人工的に生成しており、ローカル開発用データと採点に用いるデータでは、ログ日数やユーザ数、記事数、キャンペーン数は異なりますが、クリックやアクセスの傾向をコントロールするパラメータは同じものを用いています。

### `train`と`test`以下に含まれるファイル

ある期間の閲覧ログが含まれるファイルです。
ユーザーがある記事を閲覧するとその記事内では`キャンペーン`が表示され、ユーザーは`キャンペーン`をクリックすることがあります。
各列がカンマで区切られたCSVファイルです。各列の意味と形式は以下のとおりです。

列名         | 意味                                         | 形式
----------- | -------------------------------------------  | --------------------------------
id          | レコードに対する一意なID                         | { n ∈ N \| 0 <= n < 5*10^6 }
user_id     | 閲覧者のID                                     | { n ∈ N \| 0 <= n < 10^5 }
article_id  | 閲覧された記事のID                              | { n ∈ N \| 0 <= n < 10^3 }
campaign_id | 閲覧された記事内で表示されたキャンペーンID          | { n ∈ N \| 0 <= n < 10 }
click       | クリックしたかどうかを表す`*1`                     | {0, 1}
datetime    | 閲覧のあった日時`*2`                                | `yyyy-mm-dd hh:mm:ss`
device      | 閲覧時に使用していたデバイス名                     | { pc, mobile }
os          | 閲覧時に使用していたOS名                          | { android, ios, win, mac }
browser     | 閲覧時に使用していたブラウザ名                     | { chrome, safari, firefox, ie, edge, opera, default }

- Nはゼロ以上の整数を表します。
- データに欠損はありません。 
- レコードは `datetime` に関して昇順にソートされています。
- `*1`: 表示されたキャンペーンを閲覧者がクリックすれば1、クリックしなければ0で、`train`以下のデータにのみ含まれます。
- `*2`: 日付部分はファイル名と対応しています。`test`以下のレコードは`train`以下のどのレコードよりも大きい`datetime`となっています。


以下にファイルのサンプルを示します。

`train/2019-07-01`

```
id,user_id,article_id,campaign_id,click,datetime,device,os,browser
0,0,0,1,0,2019-07-01 00:06:52,mobile,ios,safari
1,0,1,2,0,2019-07-01 00:07:11,pc,win,ie
2,1,2,0,1,2019-07-01 00:07:14,mobile,android,chrome
```

`test/2019-08-01`

```
id,user_id,article_id,campaign_id,datetime,device,os,browser
135671,1976,224,0,2019-08-01 00:04:04,mobile,ios,safari
135672,1976,439,4,2019-08-01 00:05:06,mobile,ios,safari
135673,1976,87,9,2019-08-01 00:05:56,mobile,ios,safari
```

### `category.csv`

`article_id`ごとにその記事の内容を表すカテゴリの集合が与えられるCSVファイルです。
カテゴリはメインカテゴリとサブカテゴリがあり、それぞれが半角スペース区切りで与えられます。
各列の意味と形式は以下のとおりです。

| 列名        | 意味                                               | 形式
| :--------- | :------------------------------------------------- | :-------------------------
| article_id | 記事のID                                            | { n ∈ N \| 0 <= n <= 10^3 }
| categories | メインカテゴリとサブカテゴリ                            | `メインカテゴリ サブカテゴリ`

- メインカテゴリのカーディナリティは高々20です。
- サブカテゴリのカーディナリティは高々100です。
- データに欠損はありません。 


以下にファイルのサンプルを示します。

```
article_id,categories
0,sports soccer
1,sports tennis
2,food restaurant
3,business automotive
```

### `groundtruth/no1.csv`
確認用にサンプルデータに対する答え (`submission.csv`) が与えられています。
採点時には利用できません。


## 採点基準
人工的に生成した２つのデータセット、smallとmediumをテストケースとします。これらを提出されたコードに対して入力し、得られた出力を用いてAUCを計算します。
それぞれのテストケースに対して以下の`達成条件`を満たしているかを判定します。

| テストケース | 達成条件                                                     |
| :----------- | :----------------------------------------------------------- |
| small        | - 出力形式が正しい<br />- プロセスのメモリ使用量が`4GB`以下<br />- 処理時間が`600`秒以内<br />- private scoreが`0.67`以上 |
| medium       | - 出力形式が正しい<br />- プロセスのメモリ使用量が`4GB`以下<br />- 処理時間が`600`秒以内<br />- private scoreが`0.69`以上 |

* `private score`については[問1の問題文](no1)を参照してください

全てのテストケースの`達成条件`を満たしている場合に加点となります。

また上記採点基準とは別に、提出されたコードの内容（可読性、保守性など）を用いて参考材料とする場合があります。


## フィードバック
採点時に各テストケースにおいて以下のフィードバック文のいずれかが返されます。

* `実行に成功し、結果ファイルがあることを確認しました。public score: xx`
  * 出力結果の`public score`が`xx`であることを表します
  * `public score`については[問1の問題文](no1)を参照してください
  * `private score`*以外*の達成条件は満たしていることを表します
* `コードの実行に失敗しました (Runtime Error)`
  * プロセスが正常に終了しなかったことを表します
* `コードの実行に失敗しました (Memory Limit Error)`
  * プロセスのメモリ使用量が達成条件の制限を超えたことを表します
* `コードの実行に失敗しました (Time Limit Error)`
  * 処理時間が達成条件の制限を超えたことを表します
* `コードの実行に失敗しました (Output Limit Error)`
  * プロセスの標準出力の制限を超えたことを表します
  * 標準出力の量を`10MiB`以下に減らして再提出してください
* `コードの実行に成功しましたが、結果ファイルが存在しませんでした。`
  * プロセスは正常終了したが、結果ファイルが出力されていないことを表します
* `コードの実行に成功しましたが、結果ファイルの形式が不正です。`
  * プロセスが正常終了して結果ファイルは存在するが、形式が不正であることを表します
* `サンプルのままの提出です`
  * 用意されたサンプルコードや解答例がそのまま提出されたことを表します
* `解答ファイルが提出されていません`
  * `run.sh`が提出されていないことを表します

その他、採点システム上の問題が生じた場合は下記のフィードバック文が返されます。お問い合わせ先にご連絡ください。

* `採点システムにエラーが発生しました`
  * システムのエラーです。お手数ですが本スキルチェックの案内メールに記載のお問い合わせ先にご連絡ください。


## ローカル実行方法

使用できる言語やライブラリについては [全体のREADME](../README.md) を参照してください。

ローカルでの動作確認は、Docker環境で行うことを推奨します。Docker環境を利用せずに動作確認する場合は、ファイルやディレクトリのパスの間違いやライブラリのバージョン違いに注意してください。

実行例（Pythonの場合）
```
（このREADMEがあるディレクトリをカレントディレクトリにした状態で）
docker build ../docker/python -t tester
docker run --rm -v $(pwd):/work -w /work tester sh -c "cd no1 && ./run.sh"
```

`data/submission.csv`として想定した結果が出力されることを確認してください。
